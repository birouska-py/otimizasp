{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_server = \"spark://spark-master-otmzsp:7077\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurando a sessão do Spark com as dependências e variáveis do S3A\n",
    "# .master(spark_server) \\\n",
    "# .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262\") \\\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Processa Posições Raw\") \\\n",
    "    .master(spark_server) \\\n",
    "    .config(\"spark.jars.packages\", \"io.delta:delta-spark_2.12:3.1.0,org.apache.hadoop:hadoop-aws:3.3.4\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"admin\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"minioadmin\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio-otmzsp:9000\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://b498eb9c187b:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://spark-master-otmzsp:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Processa Posições Raw</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7c2934763410>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = 's3a://raw/posicoes'\n",
    "trusted = 's3a://trusted/posicoes'\n",
    "checkpoint = 's3a://trusted/posicoes_checkpoint'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, BooleanType, ArrayType, TimestampType, FloatType\n",
    "\n",
    "# Defining the schema for the JSON\n",
    "schema = StructType([StructField(\"hr\", StringType(), True),\n",
    "                     StructField(\"l\", ArrayType(StructType([StructField(\"c\", StringType(), True),\n",
    "                                                            StructField(\"cl\", IntegerType(), True),\n",
    "                                                            StructField(\"sl\", IntegerType(), True),\n",
    "                                                            StructField(\"lt0\", StringType(), True),\n",
    "                                                            StructField(\"lt1\", StringType(), True),\n",
    "                                                            StructField(\"qv\", IntegerType(), True),\n",
    "                                                            StructField(\"vs\", ArrayType(StructType([StructField(\"p\", IntegerType(), True),\n",
    "                                                                                                    StructField(\"a\", BooleanType(), True),\n",
    "                                                                                                    StructField(\"ta\", TimestampType(), True),\n",
    "                                                                                                    StructField(\"py\", FloatType(), True),\n",
    "                                                                                                    StructField(\"px\", FloatType(), True),\n",
    "                                                                                                    StructField(\"sv\", StringType(), True),\n",
    "                                                                                                    StructField(\"is\", StringType(), True)\n",
    "                                                                                                    ])\n",
    "                                                                                        )\n",
    "                                                                        )\n",
    "                                                            ])\n",
    "                                                )\n",
    "                                )\n",
    "                    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura incremental de arquivos JSON da camada raw\n",
    "df_stream = spark.read.format(\"json\").schema(schema).load(raw + '/datepartition=2024-09-23')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|   hr|                   l|\n",
      "+-----+--------------------+\n",
      "|18:17|[{3686-10, 32934,...|\n",
      "|18:19|[{3686-10, 32934,...|\n",
      "|18:15|[{3686-10, 32934,...|\n",
      "|18:09|[{3686-10, 32934,...|\n",
      "|18:05|[{3686-10, 32934,...|\n",
      "|18:01|[{3686-10, 32934,...|\n",
      "|18:21|[{3686-10, 32934,...|\n",
      "|18:11|[{3686-10, 32934,...|\n",
      "|18:13|[{3686-10, 32934,...|\n",
      "|17:57|[{3686-10, 32934,...|\n",
      "|18:39|[{3686-10, 166, 1...|\n",
      "|18:03|[{3686-10, 32934,...|\n",
      "|17:59|[{3686-10, 32934,...|\n",
      "|18:31|[{3686-10, 32934,...|\n",
      "|18:23|[{3686-10, 32934,...|\n",
      "|18:07|[{3686-10, 32934,...|\n",
      "|18:25|[{3686-10, 32934,...|\n",
      "|17:53|[{3686-10, 32934,...|\n",
      "|18:33|[{3686-10, 32934,...|\n",
      "|18:29|[{3686-10, 32934,...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_stream.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat_ws, sha1\n",
    "from pyspark.sql.functions import (\n",
    "    explode, col, to_timestamp, when, from_utc_timestamp, to_date\n",
    ")\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "# Assumindo que 'df' é o DataFrame original carregado do JSON da SPTrans\n",
    "\n",
    "df_final = df_stream.select(\n",
    "    to_timestamp(col(\"hr\")).alias(\"veiculo_horario_referencia\"),\n",
    "    explode(\"l\").alias(\"linha\")\n",
    ").select(\n",
    "    col(\"veiculo_horario_referencia\"),\n",
    "    col(\"linha.c\").alias(\"veiculo_letreiro_completo\"),\n",
    "    col(\"linha.cl\").alias(\"veiculo_linha_codigo\"),\n",
    "    col(\"linha.sl\").alias(\"veiculo_sentido\"),\n",
    "    col(\"linha.lt0\").alias(\"veiculo_letreiro_destino\"),\n",
    "    col(\"linha.lt1\").alias(\"veiculo_letreiro_origem\"),\n",
    "    col(\"linha.qv\").alias(\"qtde_veiculos_linha\"),\n",
    "    explode(\"linha.vs\").alias(\"veiculo\")\n",
    ").select(\n",
    "    \"*\",\n",
    "    col(\"veiculo.p\").alias(\"veiculo_prefixo\"),\n",
    "    col(\"veiculo.a\").alias(\"veiculo_acessibilidade\"),\n",
    "    col(\"veiculo.ta\").alias(\"veiculo_horario_utc_captura\"),\n",
    "    col(\"veiculo.py\").cast(DoubleType()).alias(\"veiculo_latitude\"),\n",
    "    col(\"veiculo.px\").cast(DoubleType()).alias(\"veiculo_longitude\")\n",
    ").drop(\"linha\", \"veiculo\")\n",
    "\n",
    "# Tratamento do sentido do veículo\n",
    "df_final = df_final.withColumn(\n",
    "    \"veiculo_sentido\",\n",
    "    when(col(\"veiculo_sentido\") == 1, \"Bairro\")\n",
    "    .when(col(\"veiculo_sentido\") == 2, \"Centro\")\n",
    "    .otherwise(col(\"veiculo_sentido\"))\n",
    ")\n",
    "\n",
    "# Tratamento da acessibilidade\n",
    "df_final = df_final.withColumn(\n",
    "    \"veiculo_acessibilidade\",\n",
    "    when(col(\"veiculo_acessibilidade\") == \"true\", \"Acessível\")\n",
    "    .when(col(\"veiculo_acessibilidade\") == \"false\", \"Não acessível\")\n",
    "    .otherwise(\"Informação não disponível\")\n",
    ")\n",
    "\n",
    "# Converter horário UTC para horário local (São Paulo, UTC-3)\n",
    "df_final = df_final.withColumn(\n",
    "    \"veiculo_horario_local_captura\",\n",
    "    from_utc_timestamp(to_timestamp(col(\"veiculo_horario_utc_captura\")), \"America/Sao_Paulo\")\n",
    ")\n",
    "\n",
    "# Adicionar coluna com o tipo de operação da linha\n",
    "df_final = df_final.withColumn(\n",
    "    \"tipo_operacao_linha\",\n",
    "    when(col(\"veiculo_letreiro_completo\").substr(-2, 2) == \"10\", \"Linha Base\")\n",
    "    .when(col(\"veiculo_letreiro_completo\").substr(-2, 2).isin(\"21\", \"23\", \"32\", \"41\"), \"Linha de Atendimento\")\n",
    "    .otherwise(\"Outro tipo de operação\")\n",
    ")\n",
    "\n",
    "# Criar uma coluna 'id' com um identificador único usando SHA-256\n",
    "df_final = df_final.withColumn(\n",
    "    \"id\",\n",
    "    sha1(\n",
    "        concat_ws(\n",
    "            \"-\", \n",
    "            col(\"veiculo_letreiro_completo\"),\n",
    "            col(\"veiculo_linha_codigo\"),\n",
    "            col(\"veiculo_prefixo\"),\n",
    "            col(\"veiculo_horario_local_captura\"),\n",
    "            col(\"veiculo_latitude\"),\n",
    "            col(\"veiculo_longitude\")\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+-------------------------+--------------------+---------------+------------------------+-----------------------+-------------------+---------------+----------------------+---------------------------+-------------------+-------------------+-----------------------------+-------------------+--------------------+\n",
      "|veiculo_horario_referencia|veiculo_letreiro_completo|veiculo_linha_codigo|veiculo_sentido|veiculo_letreiro_destino|veiculo_letreiro_origem|qtde_veiculos_linha|veiculo_prefixo|veiculo_acessibilidade|veiculo_horario_utc_captura|   veiculo_latitude|  veiculo_longitude|veiculo_horario_local_captura|tipo_operacao_linha|                  id|\n",
      "+--------------------------+-------------------------+--------------------+---------------+------------------------+-----------------------+-------------------+---------------+----------------------+---------------------------+-------------------+-------------------+-----------------------------+-------------------+--------------------+\n",
      "|       2024-09-24 18:17:00|                  3686-10|               32934|         Centro|    TERM. PQ. D. PEDR...|          JD. SÃO PAULO|                  8|          31863|             Acessível|        2024-09-23 21:17:30| -23.55409812927246| -46.40316390991211|          2024-09-23 18:17:30|         Linha Base|1b0b389811a3a240d...|\n",
      "|       2024-09-24 18:17:00|                  3686-10|               32934|         Centro|    TERM. PQ. D. PEDR...|          JD. SÃO PAULO|                  8|          31620|             Acessível|        2024-09-23 21:17:29|-23.531356811523438| -46.51948165893555|          2024-09-23 18:17:29|         Linha Base|ab71c46938752a1de...|\n",
      "|       2024-09-24 18:17:00|                  3686-10|               32934|         Centro|    TERM. PQ. D. PEDR...|          JD. SÃO PAULO|                  8|          31864|             Acessível|        2024-09-23 21:17:04| -23.54340934753418|  -46.4232063293457|          2024-09-23 18:17:04|         Linha Base|228123ad950e1e100...|\n",
      "|       2024-09-24 18:17:00|                  3686-10|               32934|         Centro|    TERM. PQ. D. PEDR...|          JD. SÃO PAULO|                  8|          31616|             Acessível|        2024-09-23 21:17:00|-23.559946060180664| -46.40386962890625|          2024-09-23 18:17:00|         Linha Base|fc24afbeea45869dd...|\n",
      "|       2024-09-24 18:17:00|                  3686-10|               32934|         Centro|    TERM. PQ. D. PEDR...|          JD. SÃO PAULO|                  8|          31668|             Acessível|        2024-09-23 21:17:21| -23.53510284423828| -46.45521545410156|          2024-09-23 18:17:21|         Linha Base|833eb61d10c98de20...|\n",
      "|       2024-09-24 18:17:00|                  3686-10|               32934|         Centro|    TERM. PQ. D. PEDR...|          JD. SÃO PAULO|                  8|          31853|             Acessível|        2024-09-23 21:17:15|-23.559865951538086| -46.40348815917969|          2024-09-23 18:17:15|         Linha Base|519b1bde80a0ce5a9...|\n",
      "|       2024-09-24 18:17:00|                  3686-10|               32934|         Centro|    TERM. PQ. D. PEDR...|          JD. SÃO PAULO|                  8|          31805|             Acessível|        2024-09-23 21:17:31|-23.537643432617188| -46.47624588012695|          2024-09-23 18:17:31|         Linha Base|0a7793dbd26f2f81c...|\n",
      "|       2024-09-24 18:17:00|                  3686-10|               32934|         Centro|    TERM. PQ. D. PEDR...|          JD. SÃO PAULO|                  8|          31656|             Acessível|        2024-09-23 21:17:21|-23.543630599975586| -46.58858871459961|          2024-09-23 18:17:21|         Linha Base|baadcef961b63d294...|\n",
      "|       2024-09-24 18:17:00|                  9301-10|                 458|         Bairro|         PÇA. DO CORREIO|       TERM. CASA VERDE|                  3|          11984|             Acessível|        2024-09-23 21:17:29|-23.498014450073242| -46.66364669799805|          2024-09-23 18:17:29|         Linha Base|bf41fd5aed1696ccf...|\n",
      "|       2024-09-24 18:17:00|                  9301-10|                 458|         Bairro|         PÇA. DO CORREIO|       TERM. CASA VERDE|                  3|          11562|             Acessível|        2024-09-23 21:17:19|-23.535724639892578| -46.64310073852539|          2024-09-23 18:17:19|         Linha Base|6486cd54beb2761f8...|\n",
      "|       2024-09-24 18:17:00|                  9301-10|                 458|         Bairro|         PÇA. DO CORREIO|       TERM. CASA VERDE|                  3|          11563|             Acessível|        2024-09-23 21:16:51| -23.51865005493164|-46.653358459472656|          2024-09-23 18:16:51|         Linha Base|372e12d98d552d0c5...|\n",
      "|       2024-09-24 18:17:00|                  6726-10|               33961|         Centro|         JD. GAIVOTAS   |           TERM. GRAJAÚ|                  5|          66266|             Acessível|        2024-09-23 21:16:54| -23.73792266845703|-46.692562103271484|          2024-09-23 18:16:54|         Linha Base|a35ba2290d439c645...|\n",
      "|       2024-09-24 18:17:00|                  6726-10|               33961|         Centro|         JD. GAIVOTAS   |           TERM. GRAJAÚ|                  5|          66141|             Acessível|        2024-09-23 21:17:07|-23.755178451538086| -46.67670822143555|          2024-09-23 18:17:07|         Linha Base|d951054849bc5b27e...|\n",
      "|       2024-09-24 18:17:00|                  6726-10|               33961|         Centro|         JD. GAIVOTAS   |           TERM. GRAJAÚ|                  5|          66660|             Acessível|        2024-09-23 21:17:32| -23.75514793395996| -46.66720199584961|          2024-09-23 18:17:32|         Linha Base|000f153bd8567d972...|\n",
      "|       2024-09-24 18:17:00|                  6726-10|               33961|         Centro|         JD. GAIVOTAS   |           TERM. GRAJAÚ|                  5|          66651|             Acessível|        2024-09-23 21:17:19|-23.756385803222656|-46.667606353759766|          2024-09-23 18:17:19|         Linha Base|4fff638e7dcf81ee6...|\n",
      "|       2024-09-24 18:17:00|                  6726-10|               33961|         Centro|         JD. GAIVOTAS   |           TERM. GRAJAÚ|                  5|          66214|             Acessível|        2024-09-23 21:17:36|-23.753782272338867|-46.666900634765625|          2024-09-23 18:17:36|         Linha Base|cb04344074c456483...|\n",
      "|       2024-09-24 18:17:00|                  6057-10|               33916|         Centro|            TERM. GRAJAÚ|              VL. NATAL|                  6|          66029|             Acessível|        2024-09-23 21:16:02|-23.763364791870117| -46.70798110961914|          2024-09-23 18:16:02|         Linha Base|680a58ad38f120261...|\n",
      "|       2024-09-24 18:17:00|                  6057-10|               33916|         Centro|            TERM. GRAJAÚ|              VL. NATAL|                  6|          66598|             Acessível|        2024-09-23 21:16:59|-23.742210388183594|-46.706748962402344|          2024-09-23 18:16:59|         Linha Base|f32d764d1446a08f2...|\n",
      "|       2024-09-24 18:17:00|                  6057-10|               33916|         Centro|            TERM. GRAJAÚ|              VL. NATAL|                  6|          66923|             Acessível|        2024-09-23 21:17:16| -23.76604652404785|-46.708518981933594|          2024-09-23 18:17:16|         Linha Base|79805db39027600c7...|\n",
      "|       2024-09-24 18:17:00|                  6057-10|               33916|         Centro|            TERM. GRAJAÚ|              VL. NATAL|                  6|          66232|             Acessível|        2024-09-23 21:16:57| -23.73671531677246|-46.697200775146484|          2024-09-23 18:16:57|         Linha Base|476b041a52480be9b...|\n",
      "+--------------------------+-------------------------+--------------------+---------------+------------------------+-----------------------+-------------------+---------------+----------------------+---------------------------+-------------------+-------------------+-----------------------------+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3856862"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.count()\n",
    "#1802572"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "import time\n",
    "\n",
    "# Supondo que df_final já está definido e contém uma coluna 'id' e 'veiculo_horario_referencia'\n",
    "\n",
    "# Remover registros duplicados com base no campo 'id'\n",
    "df_final_unique = df_final.dropDuplicates([\"id\"])\n",
    "\n",
    "# Adiciona uma coluna com o formato 'yyyy-MM-dd-HH' baseado em veiculo_horario_referencia\n",
    "df_final_unique = df_final_unique.withColumn(\n",
    "    \"datepartition\",\n",
    "    F.date_format(F.col(\"veiculo_horario_local_captura\"), \"yyyy-MM-dd-HH\")\n",
    ")\n",
    "\n",
    "# Ajuste o número de partições, se necessário\n",
    "#df_final_unique = df_final_unique.repartition(4, \"datepartition\")\n",
    "\n",
    "# Escreve o stream em CSV particionado por 'yyyy-MM-dd-HH', onde novos dados serão continuamente adicionados\n",
    "df_final_unique.write \\\n",
    "    .format(\"csv\") \\\n",
    "    .option(\"path\", trusted) \\\n",
    "    .option(\"checkpointLocation\", checkpoint) \\\n",
    "    .partitionBy(\"datepartition\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
