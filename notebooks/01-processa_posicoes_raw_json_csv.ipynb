{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_server = \"spark://spark-master-otmzsp:7077\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurando a sessão do Spark com as dependências e variáveis do S3A\n",
    "# .master(spark_server) \\\n",
    "# .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262\") \\\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Processa Posições Raw\") \\\n",
    "    .master(spark_server) \\\n",
    "    .config(\"spark.jars.packages\", \"io.delta:delta-spark_2.12:3.1.0,org.apache.hadoop:hadoop-aws:3.3.4\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"admin\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"minioadmin\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio-otmzsp:9000\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://b498eb9c187b:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://spark-master-otmzsp:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Processa Posições Raw</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7a1ac8c4ae10>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = 's3a://raw/posicoes'\n",
    "trusted = 's3a://trusted/posicoes'\n",
    "checkpoint = 's3a://trusted/posicoes_checkpoint'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, BooleanType, ArrayType, TimestampType, FloatType\n",
    "\n",
    "# Defining the schema for the JSON\n",
    "schema = StructType([StructField(\"hr\", StringType(), True),\n",
    "                     StructField(\"l\", ArrayType(StructType([StructField(\"c\", StringType(), True),\n",
    "                                                            StructField(\"cl\", IntegerType(), True),\n",
    "                                                            StructField(\"sl\", IntegerType(), True),\n",
    "                                                            StructField(\"lt0\", StringType(), True),\n",
    "                                                            StructField(\"lt1\", StringType(), True),\n",
    "                                                            StructField(\"qv\", IntegerType(), True),\n",
    "                                                            StructField(\"vs\", ArrayType(StructType([StructField(\"p\", IntegerType(), True),\n",
    "                                                                                                    StructField(\"a\", BooleanType(), True),\n",
    "                                                                                                    StructField(\"ta\", TimestampType(), True),\n",
    "                                                                                                    StructField(\"py\", FloatType(), True),\n",
    "                                                                                                    StructField(\"px\", FloatType(), True),\n",
    "                                                                                                    StructField(\"sv\", StringType(), True),\n",
    "                                                                                                    StructField(\"is\", StringType(), True)\n",
    "                                                                                                    ])\n",
    "                                                                                        )\n",
    "                                                                        )\n",
    "                                                            ])\n",
    "                                                )\n",
    "                                )\n",
    "                    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura incremental de arquivos JSON da camada raw\n",
    "df_stream = spark.read.format(\"json\").schema(schema).load(raw + '/datepartition=2024-09-23')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|   hr|                   l|\n",
      "+-----+--------------------+\n",
      "|09:31|[{3686-10, 32934,...|\n",
      "|09:33|[{3686-10, 32934,...|\n",
      "|09:37|[{3686-10, 32934,...|\n",
      "|09:41|[{3686-10, 32934,...|\n",
      "|09:45|[{3686-10, 32934,...|\n",
      "|09:43|[{3686-10, 32934,...|\n",
      "|09:47|[{3686-10, 32934,...|\n",
      "|09:49|[{3686-10, 32934,...|\n",
      "|09:53|[{3686-10, 32934,...|\n",
      "|09:55|[{3686-10, 32934,...|\n",
      "|09:51|[{3686-10, 32934,...|\n",
      "|09:57|[{3686-10, 32934,...|\n",
      "|09:59|[{3686-10, 32934,...|\n",
      "|10:01|[{3686-10, 32934,...|\n",
      "|10:03|[{3686-10, 32934,...|\n",
      "|10:05|[{3686-10, 32934,...|\n",
      "|10:07|[{3686-10, 32934,...|\n",
      "|10:09|[{3686-10, 32934,...|\n",
      "|10:15|[{3686-10, 32934,...|\n",
      "|10:13|[{3686-10, 32934,...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_stream.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat_ws, sha1\n",
    "from pyspark.sql.functions import (\n",
    "    explode, col, to_timestamp, when, from_utc_timestamp, to_date\n",
    ")\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "# Assumindo que 'df' é o DataFrame original carregado do JSON da SPTrans\n",
    "\n",
    "df_final = df_stream.select(\n",
    "    to_timestamp(col(\"hr\")).alias(\"veiculo_horario_referencia\"),\n",
    "    explode(\"l\").alias(\"linha\")\n",
    ").select(\n",
    "    col(\"veiculo_horario_referencia\"),\n",
    "    col(\"linha.c\").alias(\"veiculo_letreiro_completo\"),\n",
    "    col(\"linha.cl\").alias(\"veiculo_linha_codigo\"),\n",
    "    col(\"linha.sl\").alias(\"veiculo_sentido\"),\n",
    "    col(\"linha.lt0\").alias(\"veiculo_letreiro_destino\"),\n",
    "    col(\"linha.lt1\").alias(\"veiculo_letreiro_origem\"),\n",
    "    col(\"linha.qv\").alias(\"qtde_veiculos_linha\"),\n",
    "    explode(\"linha.vs\").alias(\"veiculo\")\n",
    ").select(\n",
    "    \"*\",\n",
    "    col(\"veiculo.p\").alias(\"veiculo_prefixo\"),\n",
    "    col(\"veiculo.a\").alias(\"veiculo_acessibilidade\"),\n",
    "    col(\"veiculo.ta\").alias(\"veiculo_horario_utc_captura\"),\n",
    "    col(\"veiculo.py\").cast(DoubleType()).alias(\"veiculo_latitude\"),\n",
    "    col(\"veiculo.px\").cast(DoubleType()).alias(\"veiculo_longitude\")\n",
    ").drop(\"linha\", \"veiculo\")\n",
    "\n",
    "# Tratamento do sentido do veículo\n",
    "df_final = df_final.withColumn(\n",
    "    \"veiculo_sentido\",\n",
    "    when(col(\"veiculo_sentido\") == 1, \"Bairro\")\n",
    "    .when(col(\"veiculo_sentido\") == 2, \"Centro\")\n",
    "    .otherwise(col(\"veiculo_sentido\"))\n",
    ")\n",
    "\n",
    "# Tratamento da acessibilidade\n",
    "df_final = df_final.withColumn(\n",
    "    \"veiculo_acessibilidade\",\n",
    "    when(col(\"veiculo_acessibilidade\") == \"true\", \"Acessível\")\n",
    "    .when(col(\"veiculo_acessibilidade\") == \"false\", \"Não acessível\")\n",
    "    .otherwise(\"Informação não disponível\")\n",
    ")\n",
    "\n",
    "# Converter horário UTC para horário local (São Paulo, UTC-3)\n",
    "df_final = df_final.withColumn(\n",
    "    \"veiculo_horario_local_captura\",\n",
    "    from_utc_timestamp(to_timestamp(col(\"veiculo_horario_utc_captura\")), \"America/Sao_Paulo\")\n",
    ")\n",
    "\n",
    "# Adicionar coluna com o tipo de operação da linha\n",
    "df_final = df_final.withColumn(\n",
    "    \"tipo_operacao_linha\",\n",
    "    when(col(\"veiculo_letreiro_completo\").substr(-2, 2) == \"10\", \"Linha Base\")\n",
    "    .when(col(\"veiculo_letreiro_completo\").substr(-2, 2).isin(\"21\", \"23\", \"32\", \"41\"), \"Linha de Atendimento\")\n",
    "    .otherwise(\"Outro tipo de operação\")\n",
    ")\n",
    "\n",
    "# Criar uma coluna 'id' com um identificador único usando SHA-256\n",
    "df_final = df_final.withColumn(\n",
    "    \"id\",\n",
    "    sha1(\n",
    "        concat_ws(\n",
    "            \"-\", \n",
    "            col(\"veiculo_letreiro_completo\"),\n",
    "            col(\"veiculo_linha_codigo\"),\n",
    "            col(\"veiculo_prefixo\"),\n",
    "            col(\"veiculo_horario_local_captura\"),\n",
    "            col(\"veiculo_latitude\"),\n",
    "            col(\"veiculo_longitude\")\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+-------------------------+--------------------+---------------+------------------------+-----------------------+-------------------+---------------+----------------------+---------------------------+-------------------+-------------------+-----------------------------+-------------------+--------------------+\n",
      "|veiculo_horario_referencia|veiculo_letreiro_completo|veiculo_linha_codigo|veiculo_sentido|veiculo_letreiro_destino|veiculo_letreiro_origem|qtde_veiculos_linha|veiculo_prefixo|veiculo_acessibilidade|veiculo_horario_utc_captura|   veiculo_latitude|  veiculo_longitude|veiculo_horario_local_captura|tipo_operacao_linha|                  id|\n",
      "+--------------------------+-------------------------+--------------------+---------------+------------------------+-----------------------+-------------------+---------------+----------------------+---------------------------+-------------------+-------------------+-----------------------------+-------------------+--------------------+\n",
      "|       2024-09-23 09:31:00|                  3686-10|               32934|         Centro|    TERM. PQ. D. PEDR...|          JD. SÃO PAULO|                  6|          31863|             Acessível|        2024-09-23 12:31:33| -23.53384017944336| -46.45710754394531|          2024-09-23 09:31:33|         Linha Base|f3c33fe17be30fbf7...|\n",
      "|       2024-09-23 09:31:00|                  3686-10|               32934|         Centro|    TERM. PQ. D. PEDR...|          JD. SÃO PAULO|                  6|          31620|             Acessível|        2024-09-23 12:31:19|-23.547283172607422|-46.630165100097656|          2024-09-23 09:31:19|         Linha Base|f1fbd317f1ea9857f...|\n",
      "|       2024-09-23 09:31:00|                  3686-10|               32934|         Centro|    TERM. PQ. D. PEDR...|          JD. SÃO PAULO|                  6|          31864|             Acessível|        2024-09-23 12:31:08|  -23.5386905670166| -46.45065689086914|          2024-09-23 09:31:08|         Linha Base|0b47a66d211030e2e...|\n",
      "|       2024-09-23 09:31:00|                  3686-10|               32934|         Centro|    TERM. PQ. D. PEDR...|          JD. SÃO PAULO|                  6|          31616|             Acessível|        2024-09-23 12:31:00|-23.534982681274414| -46.42852020263672|          2024-09-23 09:31:00|         Linha Base|3f3326a1a0bea155e...|\n",
      "|       2024-09-23 09:31:00|                  3686-10|               32934|         Centro|    TERM. PQ. D. PEDR...|          JD. SÃO PAULO|                  6|          31853|             Acessível|        2024-09-23 12:31:33|-23.559865951538086| -46.40348815917969|          2024-09-23 09:31:33|         Linha Base|51216b6f72720031d...|\n",
      "|       2024-09-23 09:31:00|                  3686-10|               32934|         Centro|    TERM. PQ. D. PEDR...|          JD. SÃO PAULO|                  6|          31805|             Acessível|        2024-09-23 12:30:59|-23.529804229736328|-46.509620666503906|          2024-09-23 09:30:59|         Linha Base|e9ec78c373bdb7255...|\n",
      "|       2024-09-23 09:31:00|                  6726-10|                1193|         Bairro|         JD. GAIVOTAS   |           TERM. GRAJAÚ|                 12|          66266|             Acessível|        2024-09-23 12:30:58|-23.734670639038086|-46.662689208984375|          2024-09-23 09:30:58|         Linha Base|b2cb2482dd94e7a08...|\n",
      "|       2024-09-23 09:31:00|                  6726-10|                1193|         Bairro|         JD. GAIVOTAS   |           TERM. GRAJAÚ|                 12|          66093|             Acessível|        2024-09-23 12:31:08|-23.736597061157227|-46.697105407714844|          2024-09-23 09:31:08|         Linha Base|a1d8f7c0a75f60622...|\n",
      "|       2024-09-23 09:31:00|                  6726-10|                1193|         Bairro|         JD. GAIVOTAS   |           TERM. GRAJAÚ|                 12|          66012|             Acessível|        2024-09-23 12:31:26|-23.736597061157227|-46.697105407714844|          2024-09-23 09:31:26|         Linha Base|a08143d602f64dfd9...|\n",
      "|       2024-09-23 09:31:00|                  6726-10|                1193|         Bairro|         JD. GAIVOTAS   |           TERM. GRAJAÚ|                 12|          66172|             Acessível|        2024-09-23 12:31:28|-23.736597061157227|-46.697105407714844|          2024-09-23 09:31:28|         Linha Base|65bd4df5bd01cca65...|\n",
      "|       2024-09-23 09:31:00|                  6726-10|                1193|         Bairro|         JD. GAIVOTAS   |           TERM. GRAJAÚ|                 12|          66967|             Acessível|        2024-09-23 12:31:03|-23.736597061157227|-46.697105407714844|          2024-09-23 09:31:03|         Linha Base|6fdb43566bbef402e...|\n",
      "|       2024-09-23 09:31:00|                  6726-10|                1193|         Bairro|         JD. GAIVOTAS   |           TERM. GRAJAÚ|                 12|          66141|             Acessível|        2024-09-23 12:31:26|-23.736597061157227|-46.697105407714844|          2024-09-23 09:31:26|         Linha Base|c64078908efce073a...|\n",
      "|       2024-09-23 09:31:00|                  6726-10|                1193|         Bairro|         JD. GAIVOTAS   |           TERM. GRAJAÚ|                 12|          66227|             Acessível|        2024-09-23 12:31:03|-23.736597061157227|-46.697105407714844|          2024-09-23 09:31:03|         Linha Base|5cb6baa0044b46495...|\n",
      "|       2024-09-23 09:31:00|                  6726-10|                1193|         Bairro|         JD. GAIVOTAS   |           TERM. GRAJAÚ|                 12|          66660|             Acessível|        2024-09-23 12:31:08|-23.736597061157227|-46.697105407714844|          2024-09-23 09:31:08|         Linha Base|c582257a689697472...|\n",
      "|       2024-09-23 09:31:00|                  6726-10|                1193|         Bairro|         JD. GAIVOTAS   |           TERM. GRAJAÚ|                 12|          66918|             Acessível|        2024-09-23 12:31:12|-23.744211196899414| -46.66482162475586|          2024-09-23 09:31:12|         Linha Base|2418375240b234873...|\n",
      "|       2024-09-23 09:31:00|                  6726-10|                1193|         Bairro|         JD. GAIVOTAS   |           TERM. GRAJAÚ|                 12|          66142|             Acessível|        2024-09-23 12:31:33|-23.736072540283203| -46.69646072387695|          2024-09-23 09:31:33|         Linha Base|c07bd0ee0c3c95636...|\n",
      "|       2024-09-23 09:31:00|                  6726-10|                1193|         Bairro|         JD. GAIVOTAS   |           TERM. GRAJAÚ|                 12|          66651|             Acessível|        2024-09-23 12:31:34| -23.73455047607422| -46.66311264038086|          2024-09-23 09:31:34|         Linha Base|a2e30d2163324fcc0...|\n",
      "|       2024-09-23 09:31:00|                  6726-10|                1193|         Bairro|         JD. GAIVOTAS   |           TERM. GRAJAÚ|                 12|          66962|             Acessível|        2024-09-23 12:31:23|-23.753625869750977|-46.688194274902344|          2024-09-23 09:31:23|         Linha Base|fa47243b54d9c6656...|\n",
      "|       2024-09-23 09:31:00|                  6L01-10|               33939|         Centro|          TERM. VARGINHA|               MARSILAC|                 10|          66029|             Acessível|        2024-09-23 12:31:22| -23.81244468688965| -46.73588180541992|          2024-09-23 09:31:22|         Linha Base|eab6e0630c6522e82...|\n",
      "|       2024-09-23 09:31:00|                  6L01-10|               33939|         Centro|          TERM. VARGINHA|               MARSILAC|                 10|          66611|             Acessível|        2024-09-23 12:30:53| -23.90671157836914| -46.70845413208008|          2024-09-23 09:30:53|         Linha Base|0e29d3e7ba5700e5b...|\n",
      "+--------------------------+-------------------------+--------------------+---------------+------------------------+-----------------------+-------------------+---------------+----------------------+---------------------------+-------------------+-------------------+-----------------------------+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1802572"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "import time\n",
    "\n",
    "# Supondo que df_final já está definido e contém uma coluna 'id' e 'veiculo_horario_referencia'\n",
    "\n",
    "# Remover registros duplicados com base no campo 'id'\n",
    "df_final_unique = df_final.dropDuplicates([\"id\"])\n",
    "\n",
    "# Adiciona uma coluna com o formato 'yyyy-MM-dd-HH' baseado em veiculo_horario_referencia\n",
    "df_final_unique = df_final_unique.withColumn(\n",
    "    \"datepartition\",\n",
    "    F.date_format(F.col(\"veiculo_horario_local_captura\"), \"yyyy-MM-dd-HH\")\n",
    ")\n",
    "\n",
    "# Ajuste o número de partições, se necessário\n",
    "#df_final_unique = df_final_unique.repartition(4, \"datepartition\")\n",
    "\n",
    "# Escreve o stream em CSV particionado por 'yyyy-MM-dd-HH', onde novos dados serão continuamente adicionados\n",
    "df_final_unique.write \\\n",
    "    .format(\"csv\") \\\n",
    "    .option(\"path\", trusted) \\\n",
    "    .option(\"checkpointLocation\", checkpoint) \\\n",
    "    .partitionBy(\"datepartition\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .save()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
